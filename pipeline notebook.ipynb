{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9194914,"sourceType":"datasetVersion","datasetId":5558660}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Financial and Risk Prediction Pipeline\n#This notebook is designed to build a versatile pipeline that can handle predictions related to fraud detection, loan defaults, customer predictions, and other financial risk modeling tasks. The pipeline will include feature alignment, scaling, and model predictions.\n\n# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.base import BaseEstimator, TransformerMixin\nimport joblib\n\n# Additional imports for evaluation and visualization\nfrom sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-18T05:57:29.883389Z","iopub.execute_input":"2024-08-18T05:57:29.884754Z","iopub.status.idle":"2024-08-18T05:57:29.892549Z","shell.execute_reply.started":"2024-08-18T05:57:29.884710Z","shell.execute_reply":"2024-08-18T05:57:29.891006Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Standard feature list for the pipeline\nstandard_features = [\n    'Transaction_Frequency', 'Spending_Patterns', 'Time_Since_Last_Transaction',  # Behavioral Patterns\n    'Previous_Fraud_Flag', 'Account_Age_Days', 'Location_Deviation',  # Risk Indicators\n    'Customer_Segment', 'Account_Balance_Risk_Score',  # User/Account-Based Features\n    'Is_Transaction_Anomalous', 'Failed_Login_Attempts',  # Anomaly Detection\n    'Device_Consistency_Flag', 'IP_Address_Change_Flag',  # Device and Network Information\n    'Global_Avg_Transaction_Amount', 'Fraud_Rate_In_Similar_Transactions',  # Aggregated Features\n    'Hour_of_Day', 'Day_of_Week', 'Transaction_Amount'  # Temporal and Numerical Features\n]\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T06:00:51.124234Z","iopub.execute_input":"2024-08-18T06:00:51.124786Z","iopub.status.idle":"2024-08-18T06:00:51.133274Z","shell.execute_reply.started":"2024-08-18T06:00:51.124748Z","shell.execute_reply":"2024-08-18T06:00:51.131535Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class FeatureAligner(BaseEstimator, TransformerMixin):\n    def __init__(self, standard_features):\n        self.standard_features = standard_features\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        # Reindex the dataframe to include all standard features, fill missing ones with 0\n        aligned_df = X.reindex(columns=self.standard_features, fill_value=0)\n        return aligned_df\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T06:00:58.037247Z","iopub.execute_input":"2024-08-18T06:00:58.037720Z","iopub.status.idle":"2024-08-18T06:00:58.045886Z","shell.execute_reply.started":"2024-08-18T06:00:58.037687Z","shell.execute_reply":"2024-08-18T06:00:58.044346Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"pipeline = Pipeline([\n    ('feature_aligner', FeatureAligner(standard_features=standard_features)),  # Align features\n    ('scaler', StandardScaler()),  # Scale the features\n    ('model', RandomForestClassifier())  # Placeholder model (can be replaced)\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T06:01:01.992297Z","iopub.execute_input":"2024-08-18T06:01:01.993430Z","iopub.status.idle":"2024-08-18T06:01:02.000136Z","shell.execute_reply.started":"2024-08-18T06:01:01.993382Z","shell.execute_reply":"2024-08-18T06:01:01.998561Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import os\nimport joblib\n\n# Upload the model and scaler (adjust the paths based on your file locations)\nmodel_path = '/kaggle/input/model-and-scaler/DatosX-Meta.pkl'  # Adjust this path\nscaler_path = '/kaggle/input/model-and-scaler/new_fraud_detection_scaler (3).pkl'  # Adjust this path\n\n# Load the pre-trained model and scaler\nif os.path.exists(model_path):\n    pre_trained_model = joblib.load(model_path)\n    print(\"Model loaded successfully.\")\nelse:\n    print(\"Model file not found.\")\n\nif os.path.exists(scaler_path):\n    pre_trained_scaler = joblib.load(scaler_path)\n    print(\"Scaler loaded successfully.\")\nelse:\n    print(\"Scaler file not found.\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the pipeline for future use\njoblib.dump(pipeline, 'financial_risk_pipeline.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T06:03:28.512218Z","iopub.execute_input":"2024-08-18T06:03:28.513077Z","iopub.status.idle":"2024-08-18T06:03:28.532009Z","shell.execute_reply.started":"2024-08-18T06:03:28.513027Z","shell.execute_reply":"2024-08-18T06:03:28.530165Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['financial_risk_pipeline.pkl']"},"metadata":{}}]}]}