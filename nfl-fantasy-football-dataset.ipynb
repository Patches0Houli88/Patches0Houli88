{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9206989,"sourceType":"datasetVersion","datasetId":5566871},{"sourceId":9207674,"sourceType":"datasetVersion","datasetId":5567334}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1: Import Libraries\nHere we are going to import our necessary libraries. ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-30T07:12:45.901760Z","iopub.execute_input":"2024-08-30T07:12:45.902168Z","iopub.status.idle":"2024-08-30T07:12:45.913402Z","shell.execute_reply.started":"2024-08-30T07:12:45.902138Z","shell.execute_reply":"2024-08-30T07:12:45.911740Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset4/nfl_season_data (4).csv\n/kaggle/input/mergedffdata/nfl_season_data.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Check the NFL_Data_Py Index\n* Here we used the NFL Data Py index to start collecting our data from seasons dating back to 2020. \n* We want to make sure we make the right calls to collect the necessary data. ","metadata":{}},{"cell_type":"code","source":"import nfl_data_py as nfl\n\n# Load weekly data for the years you want\nweekly_data = nfl.import_weekly_data([2020, 2021, 2022, 2023])\n\n# Display all available columns to identify the correct names\nprint(weekly_data.columns)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:41.643067Z","iopub.execute_input":"2024-08-20T05:26:41.643853Z","iopub.status.idle":"2024-08-20T05:26:47.897641Z","shell.execute_reply.started":"2024-08-20T05:26:41.643817Z","shell.execute_reply":"2024-08-20T05:26:47.896594Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downcasting floats.\nIndex(['player_id', 'player_name', 'player_display_name', 'position',\n       'position_group', 'headshot_url', 'recent_team', 'season', 'week',\n       'season_type', 'opponent_team', 'completions', 'attempts',\n       'passing_yards', 'passing_tds', 'interceptions', 'sacks', 'sack_yards',\n       'sack_fumbles', 'sack_fumbles_lost', 'passing_air_yards',\n       'passing_yards_after_catch', 'passing_first_downs', 'passing_epa',\n       'passing_2pt_conversions', 'pacr', 'dakota', 'carries', 'rushing_yards',\n       'rushing_tds', 'rushing_fumbles', 'rushing_fumbles_lost',\n       'rushing_first_downs', 'rushing_epa', 'rushing_2pt_conversions',\n       'receptions', 'targets', 'receiving_yards', 'receiving_tds',\n       'receiving_fumbles', 'receiving_fumbles_lost', 'receiving_air_yards',\n       'receiving_yards_after_catch', 'receiving_first_downs', 'receiving_epa',\n       'receiving_2pt_conversions', 'racr', 'target_share', 'air_yards_share',\n       'wopr', 'special_teams_tds', 'fantasy_points', 'fantasy_points_ppr'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Using NFL_Data_Py For Fantasy Prediction Dataset. \nHere we began merging our data into on set and verifying all of our columns merged successfully. We also want to go through and check for duplicates. ","metadata":{}},{"cell_type":"code","source":"# Verify your columns are present and named correctly. \nprint(players.head())\nprint(players.columns)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Strip any leading or trailing spaces from column names\nplayers.columns = players.columns.str.strip()\n\n# Now try the merge again\nmerged_fantasy = pd.merge(\n    fantasy_data, \n    players[['player_id', 'player_name', 'position', 'team']], \n    on='player_id', \n    how='left'\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.939402Z","iopub.status.idle":"2024-08-20T05:26:47.939854Z","shell.execute_reply.started":"2024-08-20T05:26:47.939652Z","shell.execute_reply":"2024-08-20T05:26:47.939670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(players['player_id'].dtype)\nprint(fantasy_data['player_id'].dtype)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.941779Z","iopub.status.idle":"2024-08-20T05:26:47.942167Z","shell.execute_reply.started":"2024-08-20T05:26:47.941987Z","shell.execute_reply":"2024-08-20T05:26:47.942004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform a basic merge with just player_id and team\ntest_merge = pd.merge(\n    fantasy_data, \n    players[['player_id', 'team']], \n    on='player_id', \n    how='left'\n)\n\nprint(test_merge.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.943397Z","iopub.status.idle":"2024-08-20T05:26:47.943820Z","shell.execute_reply.started":"2024-08-20T05:26:47.943630Z","shell.execute_reply":"2024-08-20T05:26:47.943647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Strip any spaces again, just to be certain\nplayers.columns = players.columns.str.strip()\n\n# Display the columns to verify\nprint(players.columns)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.944851Z","iopub.status.idle":"2024-08-20T05:26:47.945188Z","shell.execute_reply.started":"2024-08-20T05:26:47.945028Z","shell.execute_reply":"2024-08-20T05:26:47.945042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(players[['player_id', 'player_name', 'position', 'team']].head(10))\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.946668Z","iopub.status.idle":"2024-08-20T05:26:47.947003Z","shell.execute_reply.started":"2024-08-20T05:26:47.946844Z","shell.execute_reply":"2024-08-20T05:26:47.946858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test merge with only the 'player_id' and 'team' columns\ntest_merge = pd.merge(\n    fantasy_data, \n    players[['player_id', 'team']], \n    on='player_id', \n    how='left'\n)\n\nprint(test_merge.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.948155Z","iopub.status.idle":"2024-08-20T05:26:47.948495Z","shell.execute_reply.started":"2024-08-20T05:26:47.948333Z","shell.execute_reply":"2024-08-20T05:26:47.948346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if there are any weird characters or encoding issues\nprint(players['team'].unique())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.949587Z","iopub.status.idle":"2024-08-20T05:26:47.949939Z","shell.execute_reply.started":"2024-08-20T05:26:47.949767Z","shell.execute_reply":"2024-08-20T05:26:47.949782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nfl_data_py as nfl\nimport pandas as pd\n\n# Specify the relevant columns you want to include\ncolumns = [\n    'player_id', 'player_name', 'position', 'season', 'week', 'opponent_team',\n    'completions', 'attempts', 'passing_yards', 'passing_tds', 'interceptions', 'carries', \n    'rushing_yards', 'rushing_tds', 'receptions', 'targets', 'receiving_yards', 'receiving_tds', \n    'target_share', 'air_yards_share', 'wopr', 'racr', 'fantasy_points', 'fantasy_points_ppr'\n]\n\n# Load the weekly data with the relevant columns\nfantasy_data = nfl.import_weekly_data([2020, 2021, 2022, 2023], columns=columns)\n\n# Load player metadata for merging\nplayers = nfl.import_seasonal_rosters([2020, 2021, 2022, 2023])\n\n# Rename the 'team' column in the players dataset to avoid conflicts\nplayers.rename(columns={'team': 'player_team'}, inplace=True)\n\n# Perform the full merge with renamed columns\nmerged_fantasy = pd.merge(\n    fantasy_data, \n    players[['player_id', 'player_name', 'position', 'player_team']], \n    on='player_id', \n    how='left'\n)\n\n# Preview the final merged data\nprint(merged_fantasy.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.951410Z","iopub.status.idle":"2024-08-20T05:26:47.951765Z","shell.execute_reply.started":"2024-08-20T05:26:47.951599Z","shell.execute_reply":"2024-08-20T05:26:47.951615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Advanced Statistics","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Filter for the last 3 seasons and relevant positions\npositions_to_include = ['QB', 'RB', 'WR', 'TE',''K']\nfiltered_data = cleaned_data[\n    (cleaned_data['season'].isin([2021, 2022, 2023])) &\n    (cleaned_data['position_y'].isin(positions_to_include))\n]\n\n# Group by player and position, then aggregate their total fantasy points across seasons\naggregated_data = filtered_data.groupby(['player_name_y', 'position_y', 'player_team'], as_index=False).agg({\n    'fantasy_points_ppr': 'sum'\n})\n\n# Get the top 10 players for each relevant position\ntop_players_by_position = (\n    aggregated_data.groupby('position_y', group_keys=False)\n    .apply(lambda x: x.nlargest(10, 'fantasy_points_ppr'))\n    .reset_index(drop=True)\n)\n\n# Display all rows in the output (adjust as needed)\npd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\n\n# Display the top players for each position\nprint(top_players_by_position[['player_name_y', 'position_y', 'fantasy_points_ppr', 'player_team']])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.953032Z","iopub.status.idle":"2024-08-20T05:26:47.953364Z","shell.execute_reply.started":"2024-08-20T05:26:47.953203Z","shell.execute_reply":"2024-08-20T05:26:47.953217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# To gather recent injury data: \nIn the NFL and Fantasy, injuries play a huge part in a teams success or failure. We want to be able to have our model predict the likelihood of future injuries based of recent and past injury history. This one may be a bit tricky but it will be fun to see how the precitions accuracy plays out. TBD....","metadata":{}},{"cell_type":"code","source":"import nfl_data_py as nfl\nimport pandas as pd\n\n# Import injury data for the last 3 years\ninjury_data = nfl.import_injuries([2021, 2022, 2023])\n\n# Preview the injury data\nprint(injury_data.head())\n\n# Standardize the naming conventions in both datasets for better matching\ninjury_data['full_name'] = injury_data['first_name'] + ' ' + injury_data['last_name']\n\n# Merge the injury data into your existing fantasy football dataset\nmerged_data = pd.merge(\n    cleaned_data, \n    injury_data[['full_name', 'season', 'team', 'report_primary_injury', 'report_status', 'practice_status']],  # Adjust columns as needed\n    left_on=['player_name_y', 'player_team', 'season'],\n    right_on=['full_name', 'team', 'season'],\n    how='left'\n)\n\n# Preview the updated dataset\nprint(merged_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.954923Z","iopub.status.idle":"2024-08-20T05:26:47.955278Z","shell.execute_reply.started":"2024-08-20T05:26:47.955102Z","shell.execute_reply":"2024-08-20T05:26:47.955116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Steps for Cleaning Up the Merged Data:\nRemove Unnecessary Columns: You now have columns like player_name_x and player_name_y, which are duplicates. You can clean this up:","metadata":{}},{"cell_type":"code","source":"import nfl_data_py as nfl\n\n# Clean your merged dataset using the clean_nfl_data function\ncleaned_data = nfl.clean_nfl_data(merged_data)  # Note that we're assigning the output to 'cleaned_data'\n\n# Now 'cleaned_data' should be standardized\nprint(cleaned_data.head())\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.956725Z","iopub.status.idle":"2024-08-20T05:26:47.957074Z","shell.execute_reply.started":"2024-08-20T05:26:47.956906Z","shell.execute_reply":"2024-08-20T05:26:47.956923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(cleaned_data.tail(10))  # Shows the first 10 rows\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.959916Z","iopub.status.idle":"2024-08-20T05:26:47.960308Z","shell.execute_reply.started":"2024-08-20T05:26:47.960120Z","shell.execute_reply":"2024-08-20T05:26:47.960137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the cleaned dataset to a CSV file\ncleaned_data.to_csv('nfl_season_data.csv', index=False)\n\nprint('nfl_season_data.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.961711Z","iopub.status.idle":"2024-08-20T05:26:47.962109Z","shell.execute_reply.started":"2024-08-20T05:26:47.961895Z","shell.execute_reply":"2024-08-20T05:26:47.961913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nfl_data_py as nfl\nimport pandas as pd\n\n# Import weekly data for the past 3 seasons\nweekly_data = nfl.import_weekly_data([2021, 2022, 2023])\n\n# Preview the weekly data\nprint(weekly_data.head())\n\n# Merge weekly data with your existing fantasy dataset\nmerged_weekly_data = pd.merge(\n    merged_data,  # Your existing merged dataset with injury data\n    weekly_data[['player_id', 'season', 'week', 'team', 'opponent', 'game_location', 'stadium', 'fantasy_points_ppr']],  # Adjust columns as needed\n    on=['player_id', 'season', 'week', 'team'],\n    how='left'\n)\n\n# Preview the updated dataset\nprint(merged_weekly_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.963179Z","iopub.status.idle":"2024-08-20T05:26:47.963574Z","shell.execute_reply.started":"2024-08-20T05:26:47.963368Z","shell.execute_reply":"2024-08-20T05:26:47.963385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nfl_data_py as nfl\nimport pandas as pd\n# Import the schedule for the upcoming season\nupcoming_schedule = nfl.import_schedules([2024])  # Adjust the year to the upcoming season\n\n# Preview the schedule data\nprint(upcoming_schedule.head())","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.965278Z","iopub.status.idle":"2024-08-20T05:26:47.965700Z","shell.execute_reply.started":"2024-08-20T05:26:47.965486Z","shell.execute_reply":"2024-08-20T05:26:47.965502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Upcoming Projections and Matchups\nOnce our model is trained and makes accurate predicitions on our 2023 datasets we can introduce upcoming games to the model and see how it does. 2024 will be a year long test for it but we will tweak and tune so that we get the accuracy we are hoping for. ","metadata":{}},{"cell_type":"code","source":"import nfl_data_py as nfl\nimport pandas as pd\n\n# Import the schedule for the upcoming season\nupcoming_schedule = nfl.import_schedules([2024])  # Adjust the year to the upcoming season\n\n# Preview the schedule data\nprint(upcoming_schedule.head())\n\n# Load your cleaned data from a CSV file\ncleaned_data = pd.read_csv('/kaggle/input/mergedffdata/nfl_season_data.csv')\n\n# Merge the upcoming schedule with your existing fantasy data\nupcoming_data = pd.merge(\n    cleaned_data,  # Your existing dataset\n    upcoming_schedule[['week', 'home_team', 'away_team', 'gametime', 'stadium', 'weekday']],  # Corrected column names\n    left_on=['player_team'],  # Adjust if needed\n    right_on=['home_team'],  # Adjust if needed\n    how='left'\n)\n\n# Preview the updated dataset\nprint(upcoming_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.968156Z","iopub.status.idle":"2024-08-20T05:26:47.968728Z","shell.execute_reply.started":"2024-08-20T05:26:47.968434Z","shell.execute_reply":"2024-08-20T05:26:47.968460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the updated dataset to the CSV file\nupcoming_data.to_csv('/kaggle/working/nfl_season_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.970392Z","iopub.status.idle":"2024-08-20T05:26:47.970930Z","shell.execute_reply.started":"2024-08-20T05:26:47.970673Z","shell.execute_reply":"2024-08-20T05:26:47.970696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# Load the dataset\nfile_path = '/kaggle/working/nfl_season_data.csv'\nlarge_data = pd.read_csv(file_path)\n\n# Calculate approximate chunk size based on desired file size (e.g., 100 MB)\ndesired_file_size_mb = 100  # Adjust as needed\nrow_size_in_bytes = large_data.memory_usage(deep=True).sum() / len(large_data)\nrows_per_chunk = int((desired_file_size_mb * 1024 * 1024) / row_size_in_bytes)\n\n# Split the dataset into chunks\nfor i, chunk in enumerate(range(0, large_data.shape[0], rows_per_chunk)):\n    chunk_data = large_data.iloc[chunk:chunk + rows_per_chunk]\n    chunk_data.to_csv(f'/kaggle/working/nfl_season_data_part_{i}.csv', index=False)\n\n# Check saved file sizes\nfor filename in os.listdir('/kaggle/working/'):\n    if filename.startswith('nfl_season_data_part_'):\n        print(f\"{filename}: {os.path.getsize(f'/kaggle/working/{filename}') / (1024 * 1024):.2f} MB\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.972129Z","iopub.status.idle":"2024-08-20T05:26:47.972659Z","shell.execute_reply.started":"2024-08-20T05:26:47.972378Z","shell.execute_reply":"2024-08-20T05:26:47.972408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Check saved file sizes\nfor filename in os.listdir('/kaggle/working/'):\n    if filename.startswith('nfl_season_data_part_0'):\n        print(f\"{filename}: {os.path.getsize(f'/kaggle/working/{filename}') / (1024 * 1024):.2f} MB\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.973872Z","iopub.status.idle":"2024-08-20T05:26:47.974373Z","shell.execute_reply.started":"2024-08-20T05:26:47.974120Z","shell.execute_reply":"2024-08-20T05:26:47.974141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport nfl_data_py as nfl\nimport os\n\n# Directory where the split files are located\ndirectory = '/kaggle/working/'\n\n# Loop through and clean each file\nfor filename in os.listdir(directory):\n    if filename.startswith('nfl_season_data_part_'):\n        filepath = os.path.join(directory, filename)\n        \n        # Load the file\n        data = pd.read_csv(filepath)\n        \n        # Run the clean_nfl_data command\n        cleaned_data = nfl.clean_nfl_data(data)\n        \n        # Save the cleaned file\n        cleaned_filepath = filepath.replace('.csv', '_cleaned.csv')\n        cleaned_data.to_csv(cleaned_filepath, index=False)\n\n        print(f\"Cleaned and saved: {cleaned_filepath}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.976346Z","iopub.status.idle":"2024-08-20T05:26:47.976899Z","shell.execute_reply.started":"2024-08-20T05:26:47.976639Z","shell.execute_reply":"2024-08-20T05:26:47.976661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# List of your split files\nfiles = [f'/kaggle/working/nfl_season_data_part_{i}.csv' for i in range(17)]\n\n# Loop through each file, clean, and save with new names\nfor i, file in enumerate(files):\n    try:\n        # Read each CSV file with error handling\n        df = pd.read_csv(file, on_bad_lines='skip', low_memory=False)\n        \n        # Save the cleaned file with a new name\n        cleaned_file_name = f'/kaggle/working/cleaned_file_{i}.csv'\n        df.to_csv(cleaned_file_name, index=False)\n        \n        print(f'Successfully saved: {cleaned_file_name}')\n    \n    except Exception as e:\n        print(f\"Error processing file {file}: {str(e)}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.978447Z","iopub.status.idle":"2024-08-20T05:26:47.978874Z","shell.execute_reply.started":"2024-08-20T05:26:47.978680Z","shell.execute_reply":"2024-08-20T05:26:47.978699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NFL Def Statistics\nHere we will begin to collect our NFL Def stats because as you know, Defense wins championships and no team is complete without a trustworth Def holding down their team. ","metadata":{}},{"cell_type":"code","source":"# Import the defensive data for a given season\nteam_defense_data = nfl.import_defense_data([2023])  # You can change the year as needed\n\n# Save the defensive data to a CSV file\nteam_defense_data.to_csv('nfl_team_defense_data.csv', index=False)\n\n# Display the first few rows\nprint(team_defense_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.980830Z","iopub.status.idle":"2024-08-20T05:26:47.981202Z","shell.execute_reply.started":"2024-08-20T05:26:47.981031Z","shell.execute_reply":"2024-08-20T05:26:47.981046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\nbase_url = 'https://www.pro-football-reference.com/years/2023/opp.htm'\n\nall_teams_data = []\n\n# Loop through all teams for the seasons you need\nfor year in range(2020, 2024):\n    for week in range(1, 18):  # 17 weeks in each season\n        url = base_url.format(year, week)\n        response = requests.get(url)\n        soup = BeautifulSoup(response.text, 'html.parser')\n\n        # Example of extracting table data\n        table = soup.find('table', {'id': 'team_stats'})\n        if table:\n            df = pd.read_html(str(table))[0]\n            df['Year'] = year\n            df['Week'] = week\n            all_weeks_data.append(df)\n\n# Combine all the weeks into one DataFrame\ncombined_data = pd.concat(all_weeks_data, ignore_index=True)\ncombined_data.to_csv('nfl_weekly_data.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.982805Z","iopub.status.idle":"2024-08-20T05:26:47.983335Z","shell.execute_reply.started":"2024-08-20T05:26:47.983061Z","shell.execute_reply":"2024-08-20T05:26:47.983083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reload command","metadata":{}},{"cell_type":"code","source":"!pip install nfl_data_py\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.985327Z","iopub.status.idle":"2024-08-20T05:26:47.985878Z","shell.execute_reply.started":"2024-08-20T05:26:47.985615Z","shell.execute_reply":"2024-08-20T05:26:47.985639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nfl_data_py as nfl\nimport pandas as pd\n\n# Reload your merged dataset\nmerged_data = pd.read_csv('/kaggle/input/mergedffdata/nfl_season_data.csv')\n\n\n# You might also need to reload any merged datasets or functions you’ve previously defined\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.988182Z","iopub.status.idle":"2024-08-20T05:26:47.988731Z","shell.execute_reply.started":"2024-08-20T05:26:47.988447Z","shell.execute_reply":"2024-08-20T05:26:47.988470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the initial file\ndf = pd.read_csv('/kaggle/working/nfl_season_data.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T05:26:47.989867Z","iopub.status.idle":"2024-08-20T05:26:47.990409Z","shell.execute_reply.started":"2024-08-20T05:26:47.990135Z","shell.execute_reply":"2024-08-20T05:26:47.990159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nfl_data_py as nfl\nimport pandas as pd\n\n# Specify the years for which you want to import draft picks data\nyears = [2024]  # Replace with the desired years\n\n# Fetch the draft picks data for the specified years\ndraft_picks_data = nfl.import_draft_picks(years)\n\n# Convert to DataFrame (if it's not already)\ndraft_picks_df = pd.DataFrame(draft_picks_data)\n\n# Save the DataFrame to a CSV file\ndraft_picks_df.to_csv('nfl_draft_picks.csv', index=False)\n\nprint(\"NFL draft picks data saved successfully as 'nfl_draft_picks.csv'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-30T07:15:16.824259Z","iopub.execute_input":"2024-08-30T07:15:16.825321Z","iopub.status.idle":"2024-08-30T07:15:17.670138Z","shell.execute_reply.started":"2024-08-30T07:15:16.825258Z","shell.execute_reply":"2024-08-30T07:15:17.668663Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"NFL draft picks data saved successfully as 'nfl_draft_picks.csv'\n","output_type":"stream"}]}]}